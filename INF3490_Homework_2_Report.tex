\documentclass[10pt, conference, compsocconf]{IEEEtran}
\usepackage{amsmath}  
\usepackage{graphicx}
%\hyphenation{op-tical net-works semi-conduc-tor}
\begin{document}

\title{Multi-Layer Perceptron}
\author{\IEEEauthorblockN{Christopher Parker}
\IEEEauthorblockA{Biologically Inspired Computing\\
University of Oslo\\
Fall 2014\\
%Huntsville, Alabama\\
%chris@chris-parker.net
}
}
\maketitle


\begin{abstract}
I developed a single hidden layer perceptron classifier, hereafter referred to as a 'network', applied to control of a prosthesis. The input was provided as a time series of 10 samples of 4 sensors, yielding a 40-dimensional input vector. The output was 8 dimensional, and its argmax corresponded to the classification result. Test error of 2.6\% was achieved in under on minute of training. This was comparable to results using reference implementations of the support vector classifiers in the Scikit-Learn package. Hill climbing was used for parameter tuning, though I discuss that this could have been significantly improved through genetic search.

The relevant code \& example output images may be found at: 

\centerline{github.com/csp256/INF3490\_Homework\_2}
\end{abstract}

%\begin{IEEEkeywords}
%Travelling salesman, genetic algorithm, hill climbing, exhaustive search, Python, matplotlib
%\end{IEEEkeywords}
\IEEEpeerreviewmaketitle


\section{Introduction}




\section{Theory \& Algorithm Specification}

seeding and reproducibility
Data Starvation
SVC
Hill Climbing
Low pass filter
Batching
6th order one sided finite derivative
bias learning towards discriminating difficult cases
manifold hypothesis
confusion matrix, conditional probabilities
updated validation error 


\subsection{Paths and Lengths}

\subsection{Exhaustive Search}

\subsection{Greedy Search (Hill Climbing)}

\subsection{Genetic Search}


\section{Results}

\subsection{Exhaustive Search}

\subsection{Greedy Search}

\subsection{Genetic Search}

\section{Future Work}


\section{Conclusion}



\end{document}
